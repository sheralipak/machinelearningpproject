{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7dLSN2swzVuzzqb0N3Dd3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","data = pd.read_csv('spamfile.csv', encoding='latin-1')\n","\n","# Data preprocessing\n","data['v2'] = data['v2'].map({'ham': 0, 'spam': 1})\n","data['v1'] = data['v1'].fillna('')  # Replace missing values with empty string\n","X = data['v1']\n","y = data['v2']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create a vectorizer to convert text data into numerical features\n","vectorizer = CountVectorizer()\n","X_train = vectorizer.fit_transform(X_train)\n","X_test = vectorizer.transform(X_test)\n","\n","# Convert the labels to numpy arrays\n","y_train = y_train.values\n","y_test = y_test.values\n","\n","# Multinomial Naive Bayes\n","nb = MultinomialNB()\n","nb.fit(X_train, y_train)\n","nb_pred = nb.predict(X_test)\n","\n","# Logistic Regression\n","lr = LogisticRegression()\n","lr.fit(X_train, y_train)\n","lr_pred = lr.predict(X_test)\n","\n","# Decision Tree\n","dt = DecisionTreeClassifier()\n","dt.fit(X_train, y_train)\n","dt_pred = dt.predict(X_test)\n","\n","# Evaluation metrics\n","nb_accuracy = accuracy_score(y_test, nb_pred)\n","nb_precision = precision_score(y_test, nb_pred)\n","nb_recall = recall_score(y_test, nb_pred)\n","nb_f1 = f1_score(y_test, nb_pred)\n","\n","lr_accuracy = accuracy_score(y_test, lr_pred)\n","lr_precision = precision_score(y_test, lr_pred)\n","lr_recall = recall_score(y_test, lr_pred)\n","lr_f1 = f1_score(y_test, lr_pred)\n","\n","dt_accuracy = accuracy_score(y_test, dt_pred)\n","dt_precision = precision_score(y_test, dt_pred)\n","dt_recall = recall_score(y_test, dt_pred)\n","dt_f1 = f1_score(y_test, dt_pred)\n","\n","# Comparison graph\n","labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n","nb_scores = [nb_accuracy, nb_precision, nb_recall, nb_f1]\n","lr_scores = [lr_accuracy, lr_precision, lr_recall, lr_f1]\n","dt_scores = [dt_accuracy, dt_precision, dt_recall, dt_f1]\n","\n","x = np.arange(len(labels))\n","width = 0.25\n","\n","fig, ax = plt.subplots()\n","rects1 = ax.bar(x - width, nb_scores, width, label='Naive Bayes')\n","rects2 = ax.bar(x, lr_scores, width, label='Logistic Regression')\n","rects3 = ax.bar(x + width, dt_scores, width, label='Decision Tree')\n","\n","ax.set_ylabel('Scores')\n","ax.set_title('Comparison of Classification Techniques')\n","ax.set_xticks(x)\n","ax.set_xticklabels(labels)\n","ax.legend()\n","\n","fig.tight_layout()\n","plt.show()\n"],"metadata":{"id":"yIt5SgPkutAw"},"execution_count":null,"outputs":[]}]}